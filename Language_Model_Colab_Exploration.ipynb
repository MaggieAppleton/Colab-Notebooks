{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcSUZ0cR3IJDrW+cS++hzT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaggieAppleton/Colab-Notebooks/blob/main/Language_Model_Colab_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model Colab Exploration\n",
        "\n",
        "Exerimenting with calling LLM APIs in colab and creating prompt chains.\n",
        "\n",
        "## Basic Setup"
      ],
      "metadata": {
        "id": "yvY366XGPNqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install openai and anthropic with pip"
      ],
      "metadata": {
        "id": "eY7KjZmvU1Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O_pYm_FIR1py",
        "outputId": "1828eca3-03b6-436d-f769-89a67d08daed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.87.0)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.55.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Downloading anthropic-0.55.0-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.55.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get API keys from Colab secrets.  \n",
        "Declare clients for Claude and OpenAI and pass in API keys."
      ],
      "metadata": {
        "id": "M-QZGj5_U5of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import anthropic\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "anthropic_api_key = userdata.get('ANTHROPIC_API_KEY')\n",
        "\n",
        "openai_client = openai.OpenAI(api_key=openai_api_key)\n",
        "claude_client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
        "\n",
        "print(\"✅ API clients initialized!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BRRf-EYSBMP",
        "outputId": "febc0952-f8a4-4d0f-b9e9-17cd72ff5e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ API clients initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup basic functions to call Openai and Claude.  \n",
        "Pass in prompts and default models."
      ],
      "metadata": {
        "id": "dLO6Lb0xVFbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(prompt, model=\"gpt-4.1-mini-2025-04-14\"):\n",
        "  try:\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=200\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "  except Exception as e:\n",
        "    print(f\"Error calling OpenAI: {e}\")\n",
        "    return None\n",
        "\n",
        "def call_claude(prompt, model=\"claude-3-5-haiku-20241022\"):\n",
        "    \"\"\"\n",
        "    Call Anthropic's Claude API with the given prompt\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = claude_client.messages.create(\n",
        "            model=model,\n",
        "            max_tokens=200,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.content[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Claude API: {str(e)}\"\n",
        "\n",
        "print(\"✅ API functions ready!\")"
      ],
      "metadata": {
        "id": "LlGYqEdkSmNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3cf038d-bbbc-4f38-a6ad-818b7a8ed311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ API functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test prompt for both Claude and OpenAI"
      ],
      "metadata": {
        "id": "mOSl55uzVM59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Claude: {call_claude('What is the capital of France?')}\")\n",
        "print(f\"Openai: {call_openai('What is the capital of France?')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfkJRKecG-3V",
        "outputId": "c5b5a479-9f0e-475b-e298-c1deb8b39e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claude: The capital of France is Paris. Paris is located in the north-central part of the country on the Seine River and is one of the world's major cultural, artistic, and historical centers.\n",
            "Openai: The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling Claude and returning the full response object as JSON.\n",
        "\n",
        "To make JSON work in Python, you have to import it, then use `print(response.model_dump_json(indent=2))`\n",
        "\n",
        "Remember to return the response at the end of a function."
      ],
      "metadata": {
        "id": "PCB6fnYfVQZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def get_claude_response():\n",
        "  try:\n",
        "    response = claude_client.messages.create(\n",
        "      model=\"claude-3-5-haiku-20241022\",\n",
        "      max_tokens=200,\n",
        "      messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Who are the major thought leaders on consciousness and exercise?\"}\n",
        "      ]\n",
        "    )\n",
        "    # Print the response in nicely formatted JSON\n",
        "    print(response.model_dump_json(indent=2))\n",
        "    return response\n",
        "  except Exception as e:\n",
        "    print(f\"Error calling Claude API: {str(e)}\")\n",
        "    return None\n",
        "\n",
        "# Call the function and assign the returned response to a variable\n",
        "response = get_claude_response()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-WJmvSbKmTu",
        "outputId": "27a2a9af-a456-4402-f6b2-3f6598d47553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"msg_01BcEoSEztu88KvQJD1SKaz5\",\n",
            "  \"content\": [\n",
            "    {\n",
            "      \"citations\": null,\n",
            "      \"text\": \"# Thought Leaders on Consciousness and Exercise\\n\\nThis is an interesting intersection that combines two distinct fields. Some notable figures include:\\n\\n**Consciousness and Exercise Integration:**\\n- Mihaly Csikszentmihalyi (pioneered \\\"flow state\\\" research applicable to exercise)\\n- Jon Kabat-Zinn (mindfulness-based stress reduction, mindful movement)\\n- Ellen Langer (mindfulness psychology with applications to physical activity)\\n\\n**Exercise Science with Mindfulness Components:**\\n- Kelly McGonigal (psychologist exploring exercise and mental wellbeing)\\n- Dan Siegel (interpersonal neurobiology with mindful movement applications)\\n\\n**Movement Practitioners:**\\n- Moshe Feldenkrais (Feldenkrais Method connecting movement with awareness)\\n- Thomas Hanna (somatics - consciousness of the body from within)\\n\\nIf you're interested in a specific aspect of this\",\n",
            "      \"type\": \"text\"\n",
            "    }\n",
            "  ],\n",
            "  \"model\": \"claude-3-7-sonnet-20250219\",\n",
            "  \"role\": \"assistant\",\n",
            "  \"stop_reason\": \"max_tokens\",\n",
            "  \"stop_sequence\": null,\n",
            "  \"type\": \"message\",\n",
            "  \"usage\": {\n",
            "    \"cache_creation_input_tokens\": 0,\n",
            "    \"cache_read_input_tokens\": 0,\n",
            "    \"input_tokens\": 18,\n",
            "    \"output_tokens\": 200,\n",
            "    \"server_tool_use\": null,\n",
            "    \"service_tier\": \"standard\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the response text in nice markdown."
      ],
      "metadata": {
        "id": "K5bwk8nUih0c"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "210ca202",
        "outputId": "e5a2bcc3-6f7e-491a-9e41-744ea501eb35"
      },
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response.content[0].text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Thought Leaders on Consciousness and Exercise\n\nThis is an interesting intersection that combines two distinct fields. Some notable figures include:\n\n**Consciousness and Exercise Integration:**\n- Mihaly Csikszentmihalyi (pioneered \"flow state\" research applicable to exercise)\n- Jon Kabat-Zinn (mindfulness-based stress reduction, mindful movement)\n- Ellen Langer (mindfulness psychology with applications to physical activity)\n\n**Exercise Science with Mindfulness Components:**\n- Kelly McGonigal (psychologist exploring exercise and mental wellbeing)\n- Dan Siegel (interpersonal neurobiology with mindful movement applications)\n\n**Movement Practitioners:**\n- Moshe Feldenkrais (Feldenkrais Method connecting movement with awareness)\n- Thomas Hanna (somatics - consciousness of the body from within)\n\nIf you're interested in a specific aspect of this"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Workflows\n",
        "\n",
        "## 1. Prompt Chaining\n",
        "Break a task down into substeps. Each step builds on previous results. Valuable in scenarios requiring multi-step reasoning, iterative refinement, or complex information processing."
      ],
      "metadata": {
        "id": "1H8eQ6xbJnZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "def chain(input: str, prompts: List[str]) -> str:\n",
        "  \"\"\"Chain LLM calls. Pass results between steps.\"\"\"\n",
        "  result = input\n",
        "  for i, prompt in enumerate(prompts, 1):\n",
        "    print(f\"\\n-----Step {i}-----\")\n",
        "    print(f\"\\nInput: {result}\")\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    result = call_claude(f\"\\n{prompt}\\nInput: {result}\")\n",
        "    print(f\"\\nResult:\\n{result}\")\n",
        "  return result"
      ],
      "metadata": {
        "id": "IxTl3r0rWf29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Useful for:\n",
        "- Document Q&A. First extract relevant quotes, then use those as context to generate an answer\n",
        "- Review and refine generated answers. Fact-check to reduce hallucinations.\n",
        "- Debug generated code.\n",
        "- Multi-step problem solving: identify the problem, make a plan, solve each step sequentially.\n",
        "- Data processing: extract information from text, then format the information in a specific style."
      ],
      "metadata": {
        "id": "TJtxafURf2o6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1b39c1c",
        "outputId": "6497cfd8-462a-4d88-b22d-48d933d5d6f7"
      },
      "source": [
        "# Example usage of the chain function\n",
        "\n",
        "input = \"Margaret Thatcher slashed government benefits, leaving Britain's most vulnerable citizens impoverished and angry.\"\n",
        "\n",
        "prompts = [\n",
        "    \"Extract the key nouns and verbs from the following sentence. Return them as a comma-separated list.\",\n",
        "    \"Using the keywords provided, write a short, snippy tweet. Use less than 280 characters.\",\n",
        "    \"Write an ungenerous reply to this tweet. Use less than 280 characters.\"\n",
        "]\n",
        "\n",
        "# Call the chain function\n",
        "final_output = chain(input, prompts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----Step 1-----\n",
            "\n",
            "Input: Margaret Thatcher slashed government benefits, leaving Britain's most vulnerable citizens impoverished and angry.\n",
            "\n",
            "Prompt: Extract the key nouns and verbs from the following sentence. Return them as a comma-separated list.\n",
            "\n",
            "Result:\n",
            "Nouns: Margaret Thatcher, government, benefits, Britain, citizens\n",
            "Verbs: slashed, leaving, impoverished\n",
            "\n",
            "-----Step 2-----\n",
            "\n",
            "Input: Nouns: Margaret Thatcher, government, benefits, Britain, citizens\n",
            "Verbs: slashed, leaving, impoverished\n",
            "\n",
            "Prompt: Using the keywords provided, write a short, snippy tweet. Use less than 280 characters.\n",
            "\n",
            "Result:\n",
            "Thatcher slashed government benefits, leaving Britain's citizens impoverished. Her legacy? A country where the vulnerable suffer while the wealthy celebrate. #ThatcherismFailed\n",
            "\n",
            "-----Step 3-----\n",
            "\n",
            "Input: Thatcher slashed government benefits, leaving Britain's citizens impoverished. Her legacy? A country where the vulnerable suffer while the wealthy celebrate. #ThatcherismFailed\n",
            "\n",
            "Prompt: Write an ungenerous reply to this tweet. Use less than 280 characters.\n",
            "\n",
            "Result:\n",
            "She \"slashed\" benefits? Please. Thatcher rescued Britain from economic disaster after Labour's catastrophic policies. The only people \"suffering\" were those who expected handouts instead of work. Success isn't failure just because socialists say so.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Second prompt chain example"
      ],
      "metadata": {
        "id": "eJVkcUlBcjax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Parallelisation\n",
        "\n",
        "Multiple LLMs run calls at the same time"
      ],
      "metadata": {
        "id": "E12hR-9yNNlx"
      }
    }
  ]
}